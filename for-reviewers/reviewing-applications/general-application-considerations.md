---
description: >-
  These are the common considerations that reviewers take into account when
  reviewing Open Call applications.
---

# General application considerations

## Contribution and relevance to Reset goals and principles

### Organisational profile

* Where is the organisation physically and legally based?
* If the organisation is distributed, where is the main point of contact?
* Does the organisation have any conflicts of interest with Reset, the Advisory Council, Review Board, or other supported projects?
* Is the project team an organisation, community, or an individual?

### Organisational culture

* Is the organisation or its members already known to our network or within any relevant communities? If yes, what is their reputation and why?
* What are the applicant and/or organisation’s motivations?
* What are the applicant and/or organisation’s principles?

### Project profile

* What are the goals and objectives of the project?
* Is it a technology research, development, or deployment project?
* Can the project’s effort be explained to external audiences and non-technical people?
* What tools, if any, currently exist to solve this problem? How is this project different?
* What problem are they trying to solve, and is the solution strategical or tactical?
* Is the project strategically or tactically important to our goals, principles, and rationale? To other supported efforts? How?
* Does the effort have any overlap with existing Reset, Luminate, or larger Omidiyar Group supported projects?
* Is the overlap complementary or duplicative?
* What is complementary and can it be explained clearly \(i.e., geographic focus, technology, organisation profile, etc.\)?
* What are the liabilities and risks of taking on this project \(i.e., political personalities, financial concerns, technical controversial, etc.\)? 

### Human-centered / Demand-side focus

* How does the project define its “users”?
* Is the project’s effort actually relevant to its defined users?
* Does the project’s defined user base align with the priorities of Reset?
* Could other priority user groups benefit from this project?
* Are there existing users? If not, why?
* How do existing users find the user experience? Is it versatile and usable, or useful but unusable?
* What steps has the project taken to appeal to its defined users?
* Does the project have a plan to attract more users and make the project accessible \(e.g., conduct usability testing or hold training sessions\)? 
* What is the user threat model? Who are they being protected from and what are the consequences of failure?
* How is the project localised?
* How is the project representative of those it intends to help and is it appropriate? What experience does the project have with those it intends to help?

### Evaluation criteria

* Does the project measure success quantitatively or qualitatively?
* If neither, how would the project demonstrate success \(i.e., Does the project have potential quantitative or qualitative metrics\)?
* Is there a roadmap for the project? Is it public/open? If not, why?
* Does Reset have the capacity to comprehend and manage the project?

## Technical merit

* Does the project clearly articulate the technical problem, solution, and approach?
* How is the problem clearly justifiable?
* Does the project clearly articulate its technological objectives?
* Is it an open or closed development project \(i.e., open source like Android or Firefox OS, or closed like iOS\)? 
* Does a similar technical solution already exist? If so, what are the differentiating factors?
* Does the effort propose to sustain an existing technical approach? If so, is the relevant existing approach considered successful?
* Is the effort a new technical approach or improvement to an existing solution? If so, how?
* Is the effort a completely new technical approach fostering new solutions in the field?
* Does the project’s technical approach solve the problem?
* What are the limitations of the project’s technical approach and solution?
* What are the unintended or illicit uses and consequences of this technology?
* Has the project identified and/or developed any safeguards for these consequences?

### Technical human capacity 

* How many technologists are actively supporting the project?
* How many of the original technologists are still with the project?
* Is the current team sufficient to meet the project objectives?
* If more people are needed, how does the applicant plan on obtaining the additional technical expertise?
* What other responsibilities and commitments do the project technologists have?

### Technical assets 

* Is there any existing project code or technical assets?
* Is the existing code or technical assets proof of concept, academic, or production quality?

### Technical evaluation

* How does this technical approach and solution contribute to the larger technical community? How is it measured?
* How does the project make the technical development process visible?
* How is the technical development progress measured by the project?

## Cost realism, sustainability, and readiness

* Is the project receiving any other financial support? How is this information disclosed?
* Can we discuss the project with existing financial supporters?
* What in-kind support or other revenue streams is the project receiving \(i.e., volunteer developers, service or product sales, etc.\)? 
* How does the project plan to support itself in the future?
* What is the plan to sustain the project in the future? Is it reasonable and realistic?
* If Reset doesn’t support the project, will it still be realised?
* Does the project provide a detailed and realistic description of effort and schedule \(i.e., is the project capable of creating a work plan including objectives, activities, and deliverables\)?
* Is the asking amount reasonable and justified?





In terms of review considerations, please base your review solely on the merits of the project rather comparing it to others for the purposes of resource allocation. If the OTF team and yourselves find that all active proposals are worthy of support then that is what we will fund. I included 5 specific questions in the review form:

1. Are the project objectives and timeline realistic?
2. Should additional collaboration be included?
3. Are the proposed outputs tailored to improve the likelihood of third party use such as utilizing more digestible and short form formats?
4. Are there clear means of assessing the success of the project?
5. What changes or additions need to be made to the proposed effort?

Also, please note that this review is the same one as the OTF team uses. As a result, some of these questions may be less applicable. Please include any information you think is relevant regardless of whether they align with a specific question. As you might have guessed, the questions are areas where we have seen previous fellows have challenges with after the project is underway. The overall length of reviews vary considerably. Some AC members have included a few sentences whereas others include multiple paragraphs. Please know that there is no minimum or maximum nor an expectation of review length from OTF’s end. In terms of more general considerations to keep in mind:

• The fellow’s ability to contribute strategic value to the overall goals of the host and partner organizations, the Information Controls Fellowship Program, and OTF’s goals;

• The fellow’s qualifications, demonstrated skills and experience relevant to the proposed project;

• The proposed project’s fit with the host organization’s mission and the topic of the fellowship \(Information Controls\);

• The proposed project’s well-defined goals, outlined objectives, and activities;

• The host organization’s suitability, qualifications and ability to support the project and the fellow; and

• The outputs of the project and the contribution to the larger community in the form of publicly open-sourced code, creative commons licensed content, open hardware licenses, or other models that promotes universal free access to project outputs.

